{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a2aa1f",
   "metadata": {},
   "source": [
    "# Transformers- Multilingual Language Translator using MBart: A Practical Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f48018",
   "metadata": {},
   "source": [
    "## MBart(Multilingual Bidirectional and Auto-Regressive Transformers) Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c16b3e",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "### MBart is a family of models based on Facebook AI's BART (Bidirectional and Auto-Regressive Transformers) architecture. MBart is specifically designed for multilingual text generation tasks, including machine translation and text summarization, making it a versatile and powerful tool for various NLP applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc122ed",
   "metadata": {},
   "source": [
    "### Key Features and Components:\n",
    "   **Multilingual Capability:** MBart is trained on text data from multiple languages, enabling it to perform text generation tasks in various languages. This multilingual capability is especially valuable for tasks like machine translation, where it can translate between multiple language pairs.\n",
    "\n",
    "   **Conditional Generation:** MBart is used for conditional text generation tasks, meaning it can generate text based on a given input or condition. For instance, it can take an English text as input and generate a Hindi translation. It supports almost 16 Indian Languages\n",
    "\n",
    "   **Pretrained Weights:** MBart models are pretrained on large multilingual datasets, giving them a strong understanding of grammar, syntax, and semantics across multiple languages.\n",
    "\n",
    "   **Tokenizers:** Models like MBart typically come with specialized tokenizers, such as MBart50TokenizerFast, which efficiently tokenize text in multiple languages, making them suitable for batch processing.\n",
    "\n",
    "   **Fine-Tuning:** After pretrained models like MBart are available, they can be fine-tuned on specific tasks, such as translation from one language to another or summarization.\n",
    "\n",
    "   **Text Generation Quality:** MBart models are known for their ability to generate coherent and contextually relevant text in multiple languages, making them valuable for a wide range of NLP applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4596e8",
   "metadata": {},
   "source": [
    "**Significance:**\n",
    "MBart and similar models represent a significant advancement in the field of multilingual NLP. They enable seamless communication and content generation across language barriers, making information more accessible and bridging language gaps in a globalized world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58774c3",
   "metadata": {},
   "source": [
    "\n",
    "### In This Project im going to use English to Tamil language translation using pretrained MBart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023e5f9",
   "metadata": {},
   "source": [
    "### Tamil Language belongs to southern state of Tamilnadu in India,im going to implement by using MBart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc7fc955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter some sentences:Arshad is a Data Scientist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['அர்சாத் ஒரு தரவு விஞ்ஞானி']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast #library for indian languages and other country multilingual languages\n",
    "article_en = \"The head of the United Nations says there is no military solution in syria\"\n",
    "article_an='Arshad is a good Person'\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")#im using pretrained MBart\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")#input in English\n",
    "\n",
    "model_inputs = tokenizer(str(input('enter Your sentences to translate into tamil:')), return_tensors=\"pt\")#i have used input from user instead of directly passing as text\n",
    "#'pt' specifies that the output should be in PyTorch tensors\n",
    "\n",
    "# translate from English to Tamil\n",
    "generated_tokens = model.generate(\n",
    "    **model_inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"ta_IN\"]\n",
    ")\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)#decoding to tamil\n",
    "#skip_special_tokens=True specifies special tokens which are not part of the human-readable text and can interfere with the readability so i skipped that\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84634686",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "### In this project, we successfully harnessed the power of the MBart model to address the challenging task of English to Tamil language translation ,making it a valuable tool for bridging language barriers and facilitating effective communication in a multilingual world\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299cc26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
